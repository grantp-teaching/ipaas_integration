\section{Queue processor example}


A common usage pattern is that messages arrive into a queue for processing by a continuously running server process.
There are many other patterns, such as an intermittent batch process, also.

Here we have a python script \url{qprocessor.py} that receives messages from a queue \texttt{labq} and writes them to an S3 bucket \texttt{labbucket-pg}.
Although a trivial example it illustrates some important points about queues and platform services.
Code is:

\inputminted{python}{qprocessor.py}

\subsection{Setup}

Download/run \url{sqs_setup.ps1} to setup the VPC environment.

\subsection{Create bucket}

Create a bucket using the S3 API commands:
\begin{minted}{powershell}
aws s3api create-bucket --bucket labbucket-pg
# remember bucket names globally unique!
\end{minted}

\subsection{Create role}

We need a role, which we'll call \texttt{qprocessor}.
The trust policy lets EC2 assume it, same as before:

\inputminted{json}{qprocessor-trust-policy.json}

We can then create the role \texttt{qprocessor}:
\begin{minted}{powershell}
aws iam create-role --role-name qprocessor --assume-role-policy-document file://qprocessor-trust-policy.json
\end{minted}

\subsection{Access policy}

Here we will create an access policy \url{qprocessor-access-policy.json} to allow writes to our s3 bucket and reads from our queue.
Our policy looks like:

\inputminted{json}{qprocessor-access-policy.json}

Then we attach the policy onto the role as \texttt{qprocessor-Permissions}:

\begin{minted}{powershell}
aws iam put-role-policy `
--role-name qprocessor
--policy-name qprocessor-Permissions
--policy-document file://qprocessor-access-policy.json
\end{minted}

\subsection{Create instance profile}

\begin{minted}{powershell}
# create instance profile
aws iam create-instance-profile `
--instance-profile-name qprocessor-profile

# add role
aws iam add-role-to-instance-profile `
--instance-profile-name qprocessor-profile `
--role-name qprocessor
\end{minted}

\subsection{Create EC2 instance}

\begin{minted}{powershell}
# string to look up image ID
$ImageId="resolve:ssm:/aws/service/ami-amazon-linux-latest/amzn2-ami-hvm-x86_64-gp2"

# run instance
$InstanceId=( aws ec2 run-instances `
--subnet-id $SubnetId `
--instance-type t2.micro `
--security-group-ids $SGId `
--key-name LAB_KEY `
--image-id $ImageId `
--iam-instance-profile Name=qprocessor-profile `
| ConvertFrom-Json).Instances.InstanceId 

# get public IP
$PublicIpAddress = (aws ec2 describe-instances `
--instance-id $InstanceId `
| ConvertFrom-Json).Reservations.Instances.PublicIpAddress

# connect
ssh ec2-user@$PublicIpAddress
\end{minted}

\subsection{Obtain qprocessor.py}

Use curl or download on your local PC and upload via SFTP to instance.

\subsection{Modification}

Edit qprocessor.py to match the name of your bucket.

\subsection{Run qprocessor}

We can run the \texttt{qprocessor.py}:
\begin{minted}{bash}
./qprocessor.py
\end{minted}

We can use the following to resolve issues:
\begin{minted}{bash}
# install python3 if needed
sudo yum -y install python3

# make executable if needs be
chmod +x ./qprocessor.py
man chmod # to learn more about chmod

# install dependencies 
sudo pip3 install boto3
\end{minted}

\subsection{Service unit file}

Services in linux need a service unit to tell the OS how to start and run the service.

\inputminted{cfg}{qprocessor.service}

The service unit file can be either downloaded 

\subsection{Service installation}

Service installation on Linux follows a similar pattern to windows

\begin{minted}{bash}
# reload systemd unit files 
# run after any change 
sudo systemctl daemon-reload

# enable (so it starts on boot)
sudo systemctl enable qprocessor

# start
sudo systemctl start qprocessor
\end{minted}


\section{Clean-up}

Don't forget to terminate your ec2 instance, delete your bucket, delete your queue, remove the role from instance profile, remove the instance profile, remove the policy from the role, delete the role.

